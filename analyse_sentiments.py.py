# -*- coding: utf-8 -*-
"""analyse_sentiments.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ybJ-a41Y8LQBYGkFHODpuMg4JN9dn5Kc
"""

!pip install pandas numpy scikit-learn matplotlib seaborn transformers spacy nltk textblob
!python -m spacy download fr_core_news_sm

import pandas as pd
import numpy as np
import spacy
import re
from transformers import pipeline
import matplotlib.pyplot as plt
import seaborn as sns
import json
import unittest
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
from textblob import TextBlob
from collections import Counter, defaultdict

# T√©l√©chargement des ressources NLTK n√©cessaires
try:
    # NLTK est utilis√© ici principalement pour VADER et la segmentation (si spaCy ne l'est pas)
    nltk.download('vader_lexicon', quiet=True)
    nltk.download('punkt', quiet=True)
except:
    pass

# --- 1. Initialisation des Mod√®les et Ressources NLP ---

# Chargement de spacy pour le traitement en fran√ßais (T√¢che 1.2) [cite: 572]
try:
    nlp = spacy.load("fr_core_news_sm")
except OSError:
    print("Erreur: Le mod√®le spaCy 'fr_core_news_sm' n'est pas install√©. Ex√©cutez : python -m spacy download fr_core_news_sm")
    exit()

# Initialisation des pipelines de Hugging Face pour l'analyse (T√¢che 2.1 & 2.3)
# Mod√®le 1 (Polarit√©) : Multilingue pour une meilleure robustesse en fran√ßais
try:
    sentiment_classifier = pipeline(
        "sentiment-analysis",
        model="nlptown/bert-base-multilingual-uncased-sentiment", # Mod√®le 5 √©toiles
        tokenizer="nlptown/bert-base-multilingual-uncased-sentiment"
    )
except Exception as e:
    print(f"Avertissement: √âchec du chargement du mod√®le de sentiment HF. Utilisation des m√©thodes bas√©es sur lexique. Erreur: {e}")
    sentiment_classifier = None

# Mod√®le 2 (√âmotions) : Utilisation d'un mod√®le pour d√©tecter les √©motions
try:
    emotion_classifier = pipeline(
        "text-classification",
        model="j-hartmann/emotion-english-distilroberta-base",
        return_all_scores=True
    )
except Exception as e:
    print(f"Avertissement: √âchec du chargement du mod√®le d'√©motions HF. Utilisation du lexique custom. Erreur: {e}")
    emotion_classifier = None

# VADER (M√©thode 2 de polarit√©) [cite: 569]
sia = SentimentIntensityAnalyzer()

# Dictionnaire d'Aspects (T√¢che 1.3 / 2.2)
ASPECTS_DICT = {
    "Produit": ["t√©l√©phone", "produit", "qualit√©", "performance", "rapide", "sonore", "cam√©ra", "autonomie", "application", "mobile"],
    "Prix": ["prix", "co√ªt", "valeur", "√©lev√©", "cher", "abordable", "rapport qualit√©-prix"],
    "Service": ["service client", "support technique", "support", "client", "impeccable", "lent", "r√©pondre"],
    "Livraison": ["livraison", "rapidit√©", "express", "emballage", "endommag√©", "arriv√©"]
}

# Lexique Custom pour la d√©tection d'√©motions (T√¢che 2.3 - utilis√© en fallback ou pour la m√©thode Custom)
EMOTIONS_LEXIQUE = {
    "Joie / Satisfaction": ["excellent", "parfait", "impeccable", "vivement", "recommande", "satisfait", "exceptionnel"],
    "Col√®re / Frustration": ["frustr√©", "furieux", "bug", "lent", "endommag√©", "d√©√ßu"],
    "Tristesse / D√©ception": ["d√©√ßu", "d√©cevant", "d√©ception", "pas s√ªr"],
    "Peur / Inqui√©tude": ["inquiet", "anxieux", "incertain"],
    "Surprise (pos/neg)": ["surprise", "√©tonnant"],
    "D√©gout / M√©pris": ["bof", "m√©diocre", "nul", "horrible"]
}

# Donn√©es d'Entr√©e
avis_clients = [
    "Le t√©l√©phone est excellent, tr√®s rapide et l‚Äôautonomie dure toute la journ√©e. Cependant, la cam√©ra est d√©cevante et le prix trop √©lev√© √† mon go√ªt. Service client impeccable!",
    "Livraison rapide mais produit arriv√© endommag√©. Je suis tr√®s frustr√© et d√©√ßu par cette exp√©rience.",
    "Rien √† redire! Produit parfait, emballage soign√©, livraison express. Je recommande vivement!",
    "La qualit√© sonore est exceptionnelle mais l‚Äôapplication mobile bug constamment. Support technique lent √† r√©pondre.",
    "Bof... produit correct sans plus. Le rapport qualit√©-prix est moyen. Pas s√ªr de recommander."
]

# --- 2. Fonctions d'Analyse (Modulaires) ---

def map_hf_score_to_category(score_label):
    """Mappe le label du mod√®le HF (5 √©toiles) √† la cat√©gorie requise (5 cat√©gories) [cite: 1048]"""
    if '5' in score_label: return "Tr√®s Positif"
    if '4' in score_label: return "Positif"
    if '3' in score_label: return "Neutre"
    if '2' in score_label: return "N√©gatif"
    if '1' in score_label: return "Tr√®s N√©gatif"
    return "Neutre"

def get_sentiment_score_hf(text):
    """T√¢che 2.1 (M√©thode 1): Polarit√© avec mod√®le HF (score [-1, 1] normalis√©)"""
    if sentiment_classifier:
        try:
            result = sentiment_classifier(text)[0]
            star_value = int(result['label'].split()[0])
            score_m1 = (star_value - 3) / 2 # Normalise de 1 √† 5 vers -1 √† 1
            return score_m1, result['label']
        except Exception:
            return 0.0, "Neutre"
    # Fallback si le mod√®le HF n'a pas charg√©
    return TextBlob(text).sentiment.polarity, "Neutre (Fallback)"

def get_sentiment_score_vader(text):
    """T√¢che 2.1 (M√©thode 2): Polarit√© avec VADER (score [-1, 1]) [cite: 569]"""
    return sia.polarity_scores(text)['compound']

def get_sentiment_score_textblob(text):
    """T√¢che 2.1 (M√©thode 3): Polarit√© avec TextBlob (score [-1, 1]) [cite: 560]"""
    return TextBlob(text).sentiment.polarity

def analyze_document_sentiment(text):
    """T√¢che 1.1 & 2.1: Analyse compl√®te au niveau Document."""
    score_m1, label_m1 = get_sentiment_score_hf(text)
    category = map_hf_score_to_category(label_m1)

    score_m2_vader = get_sentiment_score_vader(text)
    score_m3_textblob = get_sentiment_score_textblob(text) # Utilis√© comme M3 pour la comparaison

    # Calcul de la coh√©rence entre les 3 m√©thodes [cite: 1072]
    scores = [score_m1, score_m2_vader, score_m3_textblob]
    # La coh√©rence est invers√©ment proportionnelle √† l'√©cart type des scores
    coherence = 1 - (np.std(scores) / (np.mean(np.abs(scores)) + 0.001))

    return {
        "score_hf": score_m1,
        "category": category,
        "score_vader": score_m2_vader,
        "score_textblob": score_m3_textblob,
        "coherence": coherence
    }

def split_and_analyze_sentences(text):
    """T√¢che 1.2: D√©coupage (avec spaCy) et analyse au niveau phrase."""
    doc = nlp(text)
    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]

    results = []
    category_counts = Counter()

    for sentence in sentences:
        score_m1, label_m1 = get_sentiment_score_hf(sentence)
        category = map_hf_score_to_category(label_m1)

        category_counts[category] += 1

        results.append({"phrase": sentence, "score": score_m1, "category": category})

    # Identification des phrases contradictoires [cite: 1056]
    categories = [res['category'] for res in results]
    is_contradictory = (("Tr√®s Positif" in categories or "Positif" in categories) and
                        ("Tr√®s N√©gatif" in categories or "N√©gatif" in categories))

    distribution_total = len(sentences)
    distribution_percent = {k: v / distribution_total for k, v in category_counts.items()}

    return {
        "sentences": results,
        "is_contradictory": is_contradictory,
        "distribution_percent": distribution_percent
    }

def analyze_aspect_sentiment(text):
    """T√¢che 1.3 & 2.2: Extraction et sentiment par aspect (Utilisation de spaCy pour le contexte) [cite: 1059]"""
    doc = nlp(text)
    aspect_sentiments = {}

    for aspect, keywords in ASPECTS_DICT.items():
        aspect_mentions_found = []

        # Trouver les phrases qui contiennent l'aspect (T√¢che 2.2)
        for sent in doc.sents:
            for keyword in keywords:
                if re.search(r'\b' + re.escape(keyword) + r'\b', sent.text.lower()):
                    aspect_mentions_found.append(sent.text)
                    break

        if aspect_mentions_found:
            # Analyse du sentiment sur le contexte agr√©g√© des mentions
            context = " ".join(aspect_mentions_found)
            score, _ = get_sentiment_score_hf(context)

            # Classification simple de l'aspect
            if score >= 0.2: category = "Positif"
            elif score <= -0.2: category = "N√©gatif"
            else: category = "Neutre"

            aspect_sentiments[aspect] = {
                "score": score,
                "category": category,
                "mentions_count": len(aspect_mentions_found)
            }

    return aspect_sentiments

def detect_emotions(text):
    """T√¢che 2.3: D√©tection des 6 √©motions principales et intensit√©. Utilise HF si disponible, sinon lexique."""

    if emotion_classifier:
        # M√©thode 1: Hugging Face (plus pr√©cis)
        try:
            raw_emotions = emotion_classifier(text)[0]
            # Mapping sp√©cifique pour le mod√®le roberta √©motion
            EMOTION_MAP_HF = {
                "joy": "Joie / Satisfaction", "love": "Joie / Satisfaction",
                "anger": "Col√®re / Frustration", "sadness": "Tristesse / D√©ception",
                "fear": "Peur / Inqui√©tude", "surprise": "Surprise (positive/n√©gative)"
            }

            processed_emotions = defaultdict(float)
            for item in raw_emotions:
                label = item['label'].lower()
                score = item['score']
                mapped_label = EMOTION_MAP_HF.get(label, None)
                if mapped_label:
                    processed_emotions[mapped_label] = max(processed_emotions[mapped_label], score)

        except Exception:
            # Fallback en cas de probl√®me d'ex√©cution
            processed_emotions = _detect_emotions_lexique(text)
    else:
        # M√©thode 2: Lexique Custom (T√¢che 2.3)
        processed_emotions = _detect_emotions_lexique(text)

    # Post-traitement et calcul de l'intensit√©
    if processed_emotions:
        max_intensity = max(processed_emotions.values())
    else:
        max_intensity = 0.0

    is_emotionally_charged = max_intensity > 0.7 # Seuil pour "charg√©" [cite: 1085]

    return {
        "emotions": {k: v for k, v in processed_emotions.items() if v > 0.05},
        "max_intensity": max_intensity,
        "is_emotionally_charged": is_emotionally_charged
    }

def _detect_emotions_lexique(texte):
    """Fonction helper pour la d√©tection d'√©motions par lexique (T√¢che 2.3)"""
    texte_lower = texte.lower()
    emotions_detectees = defaultdict(float)

    for emotion, mots_cles in EMOTIONS_LEXIQUE.items():
        compte = sum(1 for mot in mots_cles if re.search(r'\b' + re.escape(mot) + r'\b', texte_lower))
        if compte > 0:
            # Intensit√© normalis√©e (simplifi√©e)
            intensite = min(1.0, compte * 0.3)
            emotions_detectees[emotion] = intensite
    return emotions_detectees

# --- 3. Fonction Principale d'Ex√©cution et de Collecte ---

class AnalyseurSentimentsComplet:
    """Regroupe l'ex√©cution et la g√©n√©ration de rapports."""

    def __init__(self):
        self.resultats_globaux = []

    def analyser_avis_complet(self, avis, index):
        """Analyse compl√®te d'un avis avec tous les niveaux et types"""

        doc_analysis = analyze_document_sentiment(avis)
        sent_analysis = split_and_analyze_sentences(avis)
        aspect_analysis = analyze_aspect_sentiment(avis)
        emotion_analysis = detect_emotions(avis)

        resultat_complet = {
            "avis_id": index + 1,
            "avis_text": avis,
            # Niveau Document & Polarit√© (T1.1, T2.1)
            "doc_score_m1_hf": doc_analysis['score_hf'],
            "doc_category": doc_analysis['category'],
            "polarite_vader": doc_analysis['score_vader'],
            "polarite_textblob": doc_analysis['score_textblob'],
            "coherence_multi_methodes": doc_analysis['coherence'],
            # Niveau Phrase (T1.2)
            "sentence_data": sent_analysis['sentences'],
            "is_contradictory": sent_analysis['is_contradictory'],
            "sent_distrib_percent": sent_analysis['distribution_percent'],
            # Niveau Aspect (T1.3, T2.2)
            "aspect_sentiments": aspect_analysis,
            # D√©tection d'√âmotions (T2.3)
            "emotion_scores": emotion_analysis['emotions'],
            "max_emotion_intensity": emotion_analysis['max_intensity'],
            "is_emotionally_charged": emotion_analysis['is_emotionally_charged']
        }
        self.resultats_globaux.append(resultat_complet)
        return resultat_complet

    def analyser_tous_avis(self, avis_liste):
        """Analyse tous les avis et g√©n√®re un r√©sum√© global"""
        self.resultats_globaux = []
        print("\n--- D√©marrage de l'Analyse pour chaque Avis ---")
        for i, avis in enumerate(avis_liste):
            print(f"Analyse de l'Avis #{i+1}...")
            self.analyser_avis_complet(avis, i)

        self.generer_resume_global()
        self.generer_visualisations()
        self.exporter_resultats()

    # --- Fonctions de Reporting (T√¢ches Livrables) ---

    def generer_resume_global(self):
        """G√©n√®re un r√©sum√© statistique global (T√¢che 1.1)"""
        print("\n" + "="*50)
        print("R√âSUM√â GLOBAL DE L'ANALYSE (Statistiques et Recommandations)")
        print("="*50)

        if not self.resultats_globaux: return

        df_global = pd.DataFrame(self.resultats_globaux)

        # 1. Distribution globale des sentiments [cite: 1098]
        global_sentiment_distribution = df_global['doc_category'].value_counts(normalize=True).mul(100)
        print("\nDistribution Globale des Sentiments (Niveau Document):")
        print(global_sentiment_distribution.to_string(float_format="%.2f%%"))

        # 2. Aspect le plus critiqu√©/encens√© [cite: 1065]
        all_aspects_scores = defaultdict(list)
        for r in self.resultats_globaux:
            for aspect, details in r['aspect_sentiments'].items():
                all_aspects_scores[aspect].append(details['score'])

        df_aspects_mean = pd.Series({k: np.mean(v) for k, v in all_aspects_scores.items()}).sort_values(ascending=False)

        if not df_aspects_mean.empty:
            aspect_critique = df_aspects_mean.index[-1]
            aspect_encense = df_aspects_mean.index[0]
            print(f"\n‚ú® Aspect le plus encens√©: **{aspect_encense}** (Score: {df_aspects_mean.iloc[0]:.2f})")
            print(f"üíÄ Aspect le plus critiqu√©: **{aspect_critique}** (Score: {df_aspects_mean.iloc[-1]:.2f})")

        # 3. √âmotion dominante [cite: 1142]
        all_emotion_scores = defaultdict(list)
        for r in self.resultats_globaux:
            for emotion, score in r['emotion_scores'].items():
                all_emotion_scores[emotion].append(score)

        if all_emotion_scores:
            df_emotions = pd.Series({k: np.mean(v) for k, v in all_emotion_scores.items()}).sort_values(ascending=False)
            print(f"\n√âmotion dominante: **{df_emotions.index[0]}** (Intensit√© moyenne: {df_emotions.iloc[0]:.2f})")

        print("\nRECOMMANDATIONS (Exemple):")
        print(f"- Am√©liorer la communication sur la valeur du produit pour justifier le **{aspect_critique.upper()}**.")

    def generer_visualisations(self):
        """G√©n√®re les visualisations demand√©es (Partie 2) [cite: 1097]"""
        if not self.resultats_globaux: return

        df_global = pd.DataFrame(self.resultats_globaux)

        plt.style.use('seaborn-v0_8-whitegrid')
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Tableau de Bord - Analyse de Sentiments', fontsize=18)

        # 1. Distribution globale des sentiments
        categories = df_global['doc_category'].value_counts().reindex(["Tr√®s Positif", "Positif", "Neutre", "N√©gatif", "Tr√®s N√©gatif"], fill_value=0)
        sns.barplot(x=categories.index, y=categories.values, palette="viridis", ax=axes[0, 0])
        axes[0, 0].set_title('Distribution Globale des Sentiments')
        axes[0, 0].set_ylabel('Nombre d\'avis')

        # 2. Comparaison des M√©thodes de Polarit√©
        df_polarite = df_global[['doc_score_m1_hf', 'polarite_vader', 'polarite_textblob']].mean()
        df_polarite.index = ['HF BERT', 'VADER', 'TextBlob']
        sns.barplot(x=df_polarite.index, y=df_polarite.values, palette="Pastel1", ax=axes[0, 1])
        axes[0, 1].set_title('Score Moyen par M√©thode de Polarit√©')
        axes[0, 1].axhline(0, color='gray', linestyle='--')

        # 3. Heatmap sentiments/aspects
        aspects_data = defaultdict(list)
        for r in self.resultats_globaux:
            for aspect in ASPECTS_DICT.keys():
                aspects_data[aspect].append(r['aspect_sentiments'].get(aspect, {}).get('score', 0))

        df_aspects = pd.DataFrame(aspects_data)
        df_aspects.index = [f"Avis {r['avis_id']}" for r in self.resultats_globaux]

        if not df_aspects.empty and len(df_aspects.columns) > 1:
            sns.heatmap(df_aspects.T, annot=True, fmt='.2f', cmap='RdYlGn', center=0, ax=axes[1, 0], cbar_kws={'label': 'Score de Sentiment'})
            axes[1, 0].set_title('Heatmap Sentiments par Aspect')

        # 4. √âmotions dominantes
        all_emotion_scores = defaultdict(list)
        for r in self.resultats_globaux:
            for emotion, score in r['emotion_scores'].items():
                all_emotion_scores[emotion].append(score)

        if all_emotion_scores:
            df_emotions = pd.Series({k: np.mean(v) for k, v in all_emotion_scores.items()}).sort_values(ascending=False)
            sns.barplot(x=df_emotions.index, y=df_emotions.values, palette="tab10", ax=axes[1, 1])
            axes[1, 1].set_title('Intensit√© √âmotionnelle Moyenne')
            axes[1, 1].set_ylabel('Intensit√© moyenne')
            axes[1, 1].tick_params(axis='x', rotation=45)

        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        plt.savefig('analyse_sentiments_dashboard.png', dpi=300)
        plt.show()

    def exporter_resultats(self):
        """Exporte les r√©sultats en JSON et CSV (Partie 2) [cite: 1099]"""
        if not self.resultats_globaux: return

        # Export JSON complet
        with open('resultats_analyse_sentiments_complet.json', 'w', encoding='utf-8') as f:
            json.dump(self.resultats_globaux, f, ensure_ascii=False, indent=2)

        # Export CSV pour tableau de donn√©es
        data_csv = []
        for r in self.resultats_globaux:
            row = {
                'Avis_ID': r['avis_id'],
                'Texte': r['avis_text'][:100] + '...',
                'Cat_HF': r['doc_category'],
                'Score_HF': r['doc_score_m1_hf'],
                'Score_VADER': r['polarite_vader'],
                'Score_TextBlob': r['polarite_textblob'],
                'Coh√©rence_Multi': r['coherence_multi_methodes'],
                'Contradictions': r['is_contradictory'],
                'Charge_Emotionnelle': r['is_emotionally_charged']
            }
            # Ajouter les scores d'aspects
            for aspect in ASPECTS_DICT.keys():
                row[f'Aspect_{aspect}'] = r['aspect_sentiments'].get(aspect, {}).get('score', None)
            data_csv.append(row)

        df = pd.DataFrame(data_csv)
        df.to_csv('resultats_analyse_sentiments.csv', index=False, encoding='utf-8')

        print("\n--- Export des Livrables ---")
        print("R√©sultats export√©s en CSV (resultats_analyse_sentiments.csv) et JSON.")

# --- 4. Tests Unitaires (Partie 1, T√¢che 4 - OBLIGATOIRE) ---

class TestSentimentAnalysis(unittest.TestCase):
    """Tests unitaires pour les fonctions principales du script."""

    def test_a_document_analysis_polarity(self):
        """Teste l'analyse de polarit√© au niveau document (M√©thode HF)."""
        # Avis clairement positif
        positive_avis = "C'est la meilleure exp√©rience client que j'ai jamais eue, je suis tr√®s heureux!"
        analysis = analyze_document_sentiment(positive_avis)
        self.assertGreater(analysis['score_hf'], 0.5, "Le score HF doit √™tre fortement Positif.")
        self.assertIn(analysis['category'], ["Tr√®s Positif", "Positif"], "La cat√©gorie doit √™tre Positif.")

        # Avis clairement n√©gatif
        negative_avis = "Absolument terrible! La qualit√© est horrible et le support ne r√©pond jamais."
        analysis = analyze_document_sentiment(negative_avis)
        self.assertLess(analysis['score_hf'], -0.5, "Le score HF doit √™tre fortement N√©gatif.")
        self.assertIn(analysis['category'], ["Tr√®s N√©gatif"], "La cat√©gorie doit √™tre Tr√®s N√©gatif.")

    def test_b_sentence_analysis_contradiction(self):
        """Teste la d√©tection de phrases contradictoires (T√¢che 1.2)."""
        # Avis contradictoire (Utilisation de spaCy pour le split)
        contradictory_avis = "J'adore la performance du produit, c'est g√©nial. Par contre, le prix est horriblement cher et la batterie est nulle."
        analysis = split_and_analyze_sentences(contradictory_avis)
        self.assertTrue(analysis['is_contradictory'], "La contradiction positive/n√©gative doit √™tre d√©tect√©e.")
        self.assertEqual(len(analysis['sentences']), 2, "Doit d√©tecter 2 phrases distinctes.")

    def test_c_aspect_analysis(self):
        """Teste l'analyse par aspect (T√¢che 1.3) et la liaison aspect-sentiment."""
        avis = "Le service client √©tait impeccable, un vrai plaisir. Mais la cam√©ra est tr√®s mauvaise et la livraison fut lente."
        analysis = analyze_aspect_sentiment(avis)

        self.assertIn("Service", analysis, "L'aspect Service doit √™tre trouv√©.")
        self.assertIn("Livraison", analysis, "L'aspect Livraison doit √™tre trouv√©.")
        self.assertGreater(analysis.get("Service", {}).get("score", -1), 0.2, "Le score Service doit √™tre positif.")
        self.assertLess(analysis.get("Livraison", {}).get("score", 1), -0.2, "Le score Livraison doit √™tre n√©gatif.")

    def test_d_emotion_detection(self):
        """Teste la d√©tection d'√©motions et la charge √©motionnelle (T√¢che 2.3)."""
        emotionnel = "Je suis tellement furieux de cette livraison endommag√©e! C'est une d√©ception totale."
        analysis = detect_emotions(emotionnel)

        self.assertTrue(analysis['is_emotionally_charged'], "L'avis doit √™tre √©motionnellement charg√©.")
        self.assertIn("Col√®re / Frustration", analysis['emotions'], "L'√©motion de col√®re doit √™tre d√©tect√©e.")

# --- EX√âCUTION PRINCIPALE ---

if __name__ == "__main__":

    # 1. Ex√©cution des tests unitaires
    print("="*70)
    print("--- D√©marrage des TESTS UNITAIRES (Livrable Obligatoire) ---")
    print("="*70)
    loader = unittest.TestLoader()
    suite = loader.loadTestsFromTestCase(TestSentimentAnalysis)
    runner = unittest.TextTestRunner(verbosity=2)
    runner.run(suite)
    print("--- FIN des Tests Unitaires ---\n")

    # 2. Lancement de l'analyse compl√®te
    analyseur = AnalyseurSentimentsComplet()
    analyseur.analyser_tous_avis(avis_clients)

    # 3. Affichage des r√©sultats pour validation visuelle
    print("\n" + "="*70)
    print("=== AFFICHAGE D√âTAILL√â DE L'EXEMPLE ATTENDU (Avis #1) ===")
    print("="*70)
    avis_1_result = next(r for r in analyseur.resultats_globaux if r['avis_id'] == 1)

    # Affichage format√© (similaire √† l'exemple de sortie attendue) [cite: 1125]
    print(f"\nAvis #1:")
    print(f"  - Niveau Document: **{avis_1_result['doc_category']}** (score: {avis_1_result['doc_score_m1_hf']:.2f})")
    print(f"    (Coh√©rence Multi-M√©thodes: {avis_1_result['coherence_multi_methodes']:.2f})")
    print("  - Niveau Phrase:")
    for i, sentence in enumerate(avis_1_result['sentence_data']):
        print(f"    * Phrase {i+1}: {sentence['category']} ({sentence['score']:.2f})")
    print("  - Niveau Aspect:")
    for aspect, data in avis_1_result['aspect_sentiments'].items():
        print(f"    * {aspect}: **{data['category']}** ({data['score']:.2f})")
    print("  - √âmotions d√©tect√©es:")
    for emotion, score in avis_1_result['emotion_scores'].items():
        print(f"    * {emotion}: (intensit√©: {score:.2f})")

    print("\n ANALYSE TERMIN√âE AVEC SUCC√àS.")